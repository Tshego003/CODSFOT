titanic[titanic$Cabin=="", ]
sum(is.na(titanic$Age))
sum(is.na(titanic$Age))
###Data for analysis
titanic2 <- titanic[, c(2,3,5,6,7,8)]
###Replacing Missing Values
sum(is.na(titanic2$Age))
md <- Mode(titanic2$Age, na.rm = TRUE)
md
titanic2$Age <- ifelse(is.na(titanic2$Age), md, titanic2$Age)
sum(is.na(titanic2$Age))
###Summary statistics
head(titanic2)
summary(titanic2)
str(titanic2)
### Using various visuals to see the final data set for analysis
ggplot(titanic2, aes(Survived, Sex))+
geom_violin(trim = FALSE)+
ggtitle("survived by sex")
ggplot(titanic2, aes(Survived)) + geom_density()+ ggtitle("Survived")
ggplot(titanic2, aes(Pclass)) + geom_density()+ ggtitle("Pclass")
ggplot(titanic2, aes(Sex)) + geom_density()+ ggtitle("Sex")
ggplot(titanic2, aes(Age)) + geom_density()+ ggtitle("Age")
ggplot(titanic2, aes(SibSp)) + geom_density()+ ggtitle("SibSp")
ggplot(titanic2, aes(Parch)) + geom_density()+ ggtitle("Parch")
ggplot(data.long, aes(Sex, fill= variable))+
geom_density(alpha=0.5)+
facet_wrap(~variable, scales = "free")+
theme_minimal()
data.long <- melt(titanic2)
ggplot(data.long, aes(Sex, fill= variable))+
geom_density(alpha=0.5)+
facet_wrap(~variable, scales = "free")+
theme_minimal()
###Correlation between the variables
ggpairs(data = titanic2, columns= c(1,2, 3,4,5,6), title = "Titanic Survivors")
corrgram(titanic2, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie)
###changing survived variable into factor
new.labels <- c("Died", "Survived")
titanic2$Survived <- factor(titanic2$Survived, labels = new.labels)
table(titanic2$Survived)
titanic2$Sex <- factor(titanic2$Sex)
###training data
set.seed(101)
sample <- sample.split(titanic2$Survived, SplitRatio = 0.5)
train <- subset(titanic2, sample == TRUE)
test <- subset(titanic2, sample == FALSE)
traindata <- train[,2:6]
trainclass <- train[,1]
tr <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
titanicPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr)
confusionMatrix(titanicPredict)
rpart.plot(titanicPredict$finalModel, box.palette = "BuGn",main = "Survivors", extra = 101)
rpart.rules(titanicPredict$finalModel, cover = TRUE, clip.facs = TRUE)
TestPredict <- rpart.predict(titanicPredict,test)
table(TestPredict, test$Survived) %>%
prop.table()%>%
round(3)
###Loading Packages
library(haven)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(corrplot)
library(DescTools)
library(caTools)
library(rpart)
library(rpart.plot)
library(caret)
library(reshape2)
###Loading the Iris data set
iris <- read.csv("IRIS.csv")
###Overview of data set
summary(iris)
str(iris)
head(iris)
###Checking missing values
is.na(iris)
iris$species
iris[iris$species=="", ]
###Visualizing the data
ggplot(iris, aes(x= sepal_length))+
geom_bar()+
labs(title = "Species length", X = "Species length", y= "Count")
ggplot(iris, aes(x= factor(species), fill= factor(sepal_length)))+
geom_bar(position = "dodge")+
labs(x= "Species", y= "Count", fill= "sepal_length")+
ggtitle("Species by length")
ggplot(iris, aes(x= factor(species), fill= factor(sepal_width)))+
geom_bar(position = "dodge")+
labs(x= "Species", y= "Count", fill= "sepal_width")+
ggtitle("Species by width")
ggplot(iris, aes(x= factor(species), fill= factor(petal_length)))+
geom_bar(position = "dodge")+
labs(x= "Species", y= "Count", fill= "petal_length")+
ggtitle("Species by petal length")
ggplot(iris, aes(x= factor(species), fill= factor(petal_width)))+
geom_bar(position = "dodge")+
labs(x= "Species", y= "Count", fill= "petal_width")+
ggtitle("Species by petal width")
data_long <- melt(iris)
ggplot(data_long, aes(species, fill= variable))+
geom_density(alpha=0.6)+
facet_wrap(~variable, scales = "free")+
theme_minimal()
cor_matrix <- cor(iris[, -5])
corrplot(cor_matrix, method = "color", type = "full", order = "hclust", tl.col="black", tl.srt = 45, addrect = 2)
###Changing the species into factor
iris$species <- factor(iris$species)
###Splitting the data
set.seed(101)
sample <- sample.split(iris$species, SplitRatio = 0.5)
Iristest <- subset(iris, sample == FALSE)
Iristrain <- subset(iris, sample == TRUE)
###Modeling the data
traindata <- Iristrain[,1:4]
trainclass <- Iristrain[,5]
tr <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
IrisPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr)
confusionMatrix(IrisPredict)
rpart.plot(IrisPredict$finalModel, box.palette = "BuGn",main = "Iris", extra = 101)
rpart.rules(IrisPredict$finalModel, cover = TRUE, clip.facs = TRUE)
TestPredict <- rpart.predict(IrisPredict,Iristest)
table(TestPredict, Iristest$species) %>%
prop.table()%>%
round(2)
table(TestPredict, Iristest$species) %>%
prop.table()%>%
round(3)
###loading and checking data set
credit <- read.csv("creditcard.csv")
summary(credit)
str(credit)
head(credit)
table(credit$Class)
corr <- cor(credit)
corrplot(corr, method = "shade", type = "full", order = "original", tl.cex = 0.7, diag = FALSE, col = colorRampPalette(c("blue", "white", "turquoise", "yellow", "purple"))(10), adrect = 8, cl.cex = 0.7, number.cex = digits)
###testing and training data
set.seed(101)
sample <- sample.split(credit$Class, SplitRatio = 0.7)
credittrain <- subset(credit, sample == TRUE)
credittest <- subset(credit, sample == FALSE)
str(credittrain)
str(credittest)
###Logistic Regression
credit_glm <- glm(Class~., data = credittrain, family = binomial)
summary(credit_glm)
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, probability = TRUE)
class <- table(credittest[, 30], credit_predict> 0.5)
class
###Running Decision Tree
credittrain$Class <- factor(credittrain$Class)
traindata <- credittrain[,1:30]
trainclass <- credittrain[,31]
tr3 <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
gc()
gc()
confusionMatrix(creditPredict)
rpart.plot(creditPredict$finalModel, box.palette = "BuGn",main = "Credit Card Fraud", extra = 101)
rpart.rules(creditPredict$finalModel, cover = TRUE, clip.facs = TRUE)
TestPredict <- rpart.predict(creditPredict,credittest)
table(TestPredict, credittest$Class) %>%
prop.table()%>%
round(5)
?scale
credit <- na.omit(credit)
credit$Amount <- scale(credit$Amount)
credit <- na.omit(credit)
credit$Amount <- scale(credit$Amount)
install.packages("ROSE")
library("ROSE")
oversample <- ovun.sample(Class~.,data = credit, method = "over", N= nrow(credit), seed = 102)$data
oversampleData <- ovun.sample(Class~.,data = credit, method = "over", N= nrow(credit), seed = 102)$data
?ovun.sample
###testing and training data
set.seed(101)
sample <- sample.split(oversampleData$Class, SplitRatio = 0.8)
credittrain <- subset(oversampleData, sample == TRUE)
credittest <- subset(oversampleData, sample == FALSE)
str(credittrain)
str(credittest)
###Logistic Regression
credit_glm <- glm(Class~., data = credittrain, family = binomial)
summary(credit_glm)
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, probability = TRUE)
class <- table(credittest[, 30], credit_predict> 0.5)
class
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, probability = TRUE, type = "response")
class <- table(credittest[, 30], credit_predict> 0.5)
class
table(credittest$Class, creditPredict)
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, type = "response")
table(credittest$Class, creditPredict)
creditPredict
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, type = "response")
credit_Predict
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, type = "response")
rm(credit_predict, creditPredict)
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, type = "response")
credit_Predict
credit_predict
summary(credit_predict)
table(credittest$Class, credit_predict)
confusion.mat <- table(credittest$Class, credit_predict)
accuracy <- sum(diag(confusion.mat))/sum(confusion.mat)
accuracy
?precision
precision <- confusion.mat[2,2]/sum(confusion.mat, 2)
precision
recall <- confusion.mat[2,2]/ sum(confusion.mat[2,])
recall
f1score <- 2*precision*recall/(precision+recall)
precision()
?cat
cat("Precision", precision, \"n")
cat("Precision:", precision, \"n")
cat("Precision:", precision, "\n")
conf <- confusionMatrix(creditPredict)
###Running Decision Tree
credittrain$Class <- factor(credittrain$Class)
traindata <- credittrain[,1:30]
trainclass <- credittrain[,31]
tr3 <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
conf <- confusionMatrix(creditPredict)
conf <- confusionMatrix(creditPredict)
conf
accuracy <- sum(diag(conf))/sum(conf)
accuracy <- sum(conf)/sum(conf)
accuracy
accuracy <- sum(diag(conf))/sum(conf)
confusion.mat <- table(credittest$Class, credit_predict)
accuracy <- sum(diag(confusion.mat))/sum(confusion.mat)
accuracy
probs <- ifelse(credit_predict > 0.5, 1,0)
credit_predict<- ifelse(credit_predict > 0.5, 1,0)
confusion.mat <- table(credittest$Class, credit_predict)
accuracy <- sum(diag(confusion.mat))/sum(confusion.mat)
accuracy
precision <- confusion.mat[2,2]/sum(confusion.mat, 2)
precision
recall <- confusion.mat[2,2]/ sum(confusion.mat[2,])
recall
f1score <- 2*precision*recall/(precision+recall)
cat("Precision:", precision, "\n")
f1score <- 2*precision*recall/(precision+recall)
cat("Precision:", precision, "\n")
?diag
?scale
library(haven)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(corrplot)
library(DescTools)
library(caTools)
library(rpart)
library(rpart.plot)
library(caret)
library(reshape2)
###loading and checking data set
credit <- read.csv("creditcard.csv")
summary(credit)
str(credit)
head(credit)
table(credit$Class)
corr <- cor(credit)
corrplot(corr, method = "shade", type = "full", order = "original", tl.cex = 0.7, diag = FALSE, col = colorRampPalette(c("blue", "white", "turquoise", "yellow", "purple"))(10), adrect = 8, cl.cex = 0.7, number.cex = digits)
library(ROSE)
credit <- na.omit(credit) ### Removing missing values
credit$Amount <- scale(credit$Amount)
oversampleData <- ovun.sample(Class~.,data = credit, method = "over", N= nrow(credit), seed = 102)$data ###Handling imbalance and Oversampling
###testing and training data
set.seed(101)
sample <- sample.split(oversampleData$Class, SplitRatio = 0.8)
credittrain <- subset(oversampleData, sample == TRUE)
credittest <- subset(oversampleData, sample == FALSE)
str(credittrain)
str(credittest)
###Logistic Regression
credit_glm <- glm(Class~., data = credittrain, family = binomial) ### Running a logistic regression model
summary(credit_glm)
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, type = "response")
credit_predict<- ifelse(credit_predict > 0.5, 1,0) ### This is meant to change probabilities to binary
confusion.mat <- table(credittest$Class, credit_predict)
Creditaccuracy <- sum(diag(confusion.mat))/sum(confusion.mat) ###Calculating accuracy
accuracy
###Using test data to run prediction of logistic model
credit_predict <- predict(credit_glm, credittest, type = "response")
credit_predict<- ifelse(credit_predict > 0.5, 1,0) ### This is meant to change probabilities to binary
confusion.mat <- table(credittest$Class, credit_predict)
Creditaccuracy <- sum(diag(confusion.mat))/sum(confusion.mat) ###Calculating accuracy
Creditaccuracy
Creditprecision <- confusion.mat[2,2]/sum(confusion.mat, 2) ###Calculating Precision
precision
Creditrecall <- confusion.mat[2,2]/ sum(confusion.mat[2,]) ### Calculating recall
recall
f1score <- 2*Creditprecision*Creditrecall/(Creditprecision+Creditrecall)### Calculating F1 score
f1score
credit_predict
summary(credit_predict)
table(credit_predict)
credit_predict<- ifelse(credit_predict > 0.5, 1,0) ### This is meant to change probabilities to binary
credit_predict
credit_predict<- ifelse(credit_predict > 0.5, 1,0)
table(credit_predict)
confusion.mat <- table(credittest$Class, credit_predict)
confusion.mat
confusion.mat
Creditaccuracy <- sum(diag(confusion.mat))/sum(confusion.mat) ###Calculating accuracy
Creditaccuracy
Creditprecision <- confusion.mat[2,2]/sum(confusion.mat, 2) ###Calculating Precision
precision
Creditprecision <- confusion.mat[2,2]/sum(confusion.mat, 2) ###Calculating Precision
Creditprecision
Creditrecall <- confusion.mat[2,2]/ sum(confusion.mat[2,]) ### Calculating recall
Creditrecall
f1score <- 2*Creditprecision*Creditrecall/(Creditprecision+Creditrecall)### Calculating F1 score
f1score
###Running Decision Tree
traindata <- credittrain[,1:30]
trainclass <- credittrain[,31]
tr3 <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
confusionMatrix(creditPredict)
confusionMatrix(creditPredict)
confusionMatrix(creditPredict)
confusionMatrix(creditPredict)
###Running Decision Tree
credit$Class <- factor(credit$Class)
traindata <- credittrain[,1:30]
trainclass <- credittrain[,31]
###Running Decision Tree
credittrain$Class <- factor(credittrain$Class)
traindata <- credittrain[,1:30]
trainclass <- credittrain[,31]
tr3 <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
confusionMatrix(creditPredict)
confusionMatrix(creditPredict)
rpart.plot(creditPredict$finalModel, box.palette = "BuGn",main = "Credit Card Fraud", extra = 101)
rpart.rules(creditPredict$finalModel, cover = TRUE, clip.facs = TRUE)
TestPredict <- rpart.predict(creditPredict,credittest)
table(TestPredict, credittest$Class) %>%
prop.table()%>%
round(5)
gc()
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3,
weights = class_weights)
?train
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3,
weights = "class_weights")
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3,
weights = 4)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
###Running Decision Tree
credittrain$Class <- factor(credittrain$Class)
traindata <- credittrain[,1:30]
trainclass <- credittrain[,31]
tr3 <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
creditPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr3)
confusionMatrix(creditPredict)
rpart.plot(creditPredict$finalModel, box.palette = "BuGn",main = "Credit Card Fraud", extra = 101)
rpart.rules(creditPredict$finalModel, cover = TRUE, clip.facs = TRUE)
TestPredict <- rpart.predict(creditPredict,credittest)
table(TestPredict, credittest$Class) %>%
prop.table()%>%
round(5)
knitr::opts_chunk$set(echo = TRUE)
###Loading the Titanic data set
titanic <- read.csv("Titanic-Dataset.csv")
View(titanic)
###Overview of the Titanic data set
summary(titanic)
str(titanic)
head(titanic)
###Frequency Count
ggplot(titanic, aes(x= Survived))+
geom_bar()+
labs(title = "Survivors", X = "Survivors", y= "Count")
###Loading Packages
library(haven)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(apaTables)
library(corrgram)
library(corrplot)
library(DescTools)
library(caTools)
library(rpart)
library(rpart.plot)
library(GGally)
library(reshape2)
library(caret)
###Frequency Count
ggplot(titanic, aes(x= Survived))+
geom_bar()+
labs(title = "Survivors", X = "Survivors", y= "Count")
ggplot(titanic, aes(x= Survived, fill= Sex))+
geom_bar(position = "dodge")+
labs(x= "Survived", y= "Count", fill= "Sex")+
ggtitle("Survivors by Sex")
ggplot(titanic, aes(x= factor(Survived), fill= factor(Pclass)))+
geom_bar(position = "dodge")+
labs(x= "Survived", y= "Count", fill= "Pclass")+
ggtitle("Survivors by Class")
ggplot(titanic, aes(x= factor(Survived), fill= factor(SibSp)))+
geom_bar(position = "dodge")+
labs(x= "Survived", y= "Count", fill= "SibSp")+
ggtitle("Survivors by Sibling/Spouse")
ggplot(titanic, aes(x= Age))+
geom_histogram(binwidth = 0.5, fill = "purple", color ="grey")+
labs(title = "Age", X = "Age", y= "Count")
###checking for missing values
titanic[titanic$Name=="", ]
titanic[titanic$Sex=="", ]
titanic[titanic$Cabin=="", ]
sum(is.na(titanic$Age))
###Data for analysis
titanic2 <- titanic[, c(2,3,5,6,7,8)]
###Replacing Missing Values
sum(is.na(titanic2$Age))
md <- Mode(titanic2$Age, na.rm = TRUE)
md
titanic2$Age <- ifelse(is.na(titanic2$Age), md, titanic2$Age)
sum(is.na(titanic2$Age))
###Summary statistics
head(titanic2)
summary(titanic2)
str(titanic2)
### Using various visuals to see the final data set for analysis
ggplot(titanic2, aes(Survived, Sex))+
geom_violin(trim = FALSE)+
ggtitle("survived by sex")
ggplot(titanic2, aes(Survived)) + geom_density()+ ggtitle("Survived")
ggplot(titanic2, aes(Pclass)) + geom_density()+ ggtitle("Pclass")
ggplot(titanic2, aes(Sex)) + geom_density()+ ggtitle("Sex")
ggplot(titanic2, aes(Age)) + geom_density()+ ggtitle("Age")
ggplot(titanic2, aes(SibSp)) + geom_density()+ ggtitle("SibSp")
ggplot(titanic2, aes(Parch)) + geom_density()+ ggtitle("Parch")
data.long <- melt(titanic2)
ggplot(data.long, aes(Sex, fill= variable))+
geom_density(alpha=0.5)+
facet_wrap(~variable, scales = "free")+
theme_minimal()
###Correlation between the variables
ggpairs(data = titanic2, columns= c(1,2, 3,4,5,6), title = "Titanic Survivors")
corrgram(titanic2, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie)
###changing survived variable into factor
new.labels <- c("Died", "Survived")
titanic2$Survived <- factor(titanic2$Survived, labels = new.labels)
table(titanic2$Survived)
titanic2$Sex <- factor(titanic2$Sex)
###training data
set.seed(101)
sample <- sample.split(titanic2$Survived, SplitRatio = 0.5)
train <- subset(titanic2, sample == TRUE)
test <- subset(titanic2, sample == FALSE)
traindata <- train[,2:6]
trainclass <- train[,1]
tr <- trainControl(method = "cv", number = 5, savePredictions = TRUE)
titanicPredict <- train(traindata, trainclass,
method = "rpart",
trControl = tr)
confusionMatrix(titanicPredict)
rpart.plot(titanicPredict$finalModel, box.palette = "BuGn",main = "Survivors", extra = 101)
rpart.rules(titanicPredict$finalModel, cover = TRUE, clip.facs = TRUE)
TestPredict <- rpart.predict(titanicPredict,test)
table(TestPredict, test$Survived) %>%
prop.table()%>%
round(3)
